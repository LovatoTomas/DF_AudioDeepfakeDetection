{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79531f9e-0676-493a-8702-337f46a24fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|███████████████████████████████████████████████████| 25380/25380 [07:59<00:00, 52.97file/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths for dataset and label files\n",
    "# DATASET_PATH specifies the location of the audio files (.flac format).\n",
    "# LABEL_FILE_PATH points to the protocol file that contains labels (e.g., bona fide or spoof) for each audio file.\n",
    "DATASET_PATH = \"/mnt/c/DF/LA/ASVspoof2019_LA_train/flac\"\n",
    "LABEL_FILE_PATH = \"/mnt/c/DF/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\"\n",
    "\n",
    "# Paths for test dataset and label files\n",
    "# TEST_DATASET_PATH specifies the location of the evaluation audio files (.flac format).\n",
    "# TEST_LABEL_FILE_PATH points to the protocol file for the evaluation data.\n",
    "TEST_DATASET_PATH = \"/mnt/c/DF/LA/ASVspoof2019_LA_eval/flac\"\n",
    "TEST_LABEL_FILE_PATH = \"/mnt/c/DF/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\"\n",
    "\n",
    "# Extract features from audio files\n",
    "def extract_features(file_path, n_mfcc=20):\n",
    "    \"\"\"\n",
    "    Extract MFCC (Mel-Frequency Cepstral Coefficients) features from an audio file.\n",
    "    \n",
    "    Steps:\n",
    "    1. Load the audio file using librosa.\n",
    "    2. Compute the MFCCs, which capture the spectral characteristics of the audio.\n",
    "    3. Take the mean of the MFCC coefficients across the time axis to summarize the audio into a fixed-length feature vector.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the audio file.\n",
    "        n_mfcc (int): Number of MFCC coefficients to compute.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A fixed-length feature vector representing the audio.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(file_path, sr=None)  # Load the audio signal and its sampling rate.\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)  # Compute MFCC features.\n",
    "    return np.mean(mfcc.T, axis=0)  # Return the mean MFCC values across time.\n",
    "\n",
    "# Load labels from the label file\n",
    "def load_labels(label_file):\n",
    "    \"\"\"\n",
    "    Load labels from a protocol file. The protocol file contains mappings between file IDs and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        label_file (str): Path to the protocol file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping file IDs to labels (e.g., bona fide or spoof).\n",
    "    \"\"\"\n",
    "    labels = {}\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()  # Split the line into parts.\n",
    "            file_id, label = parts[1], parts[-1]  # Extract file ID and label.\n",
    "            labels[file_id] = label\n",
    "    return labels\n",
    "\n",
    "# Load data and extract features\n",
    "def load_and_preprocess_data(dataset_path, label_file):\n",
    "    \"\"\"\n",
    "    Load audio data and extract features based on the provided label file.\n",
    "\n",
    "    Steps:\n",
    "    1. Load labels using the `load_labels` function.\n",
    "    2. Iterate through all .flac files in the dataset directory.\n",
    "    3. For each file, extract features and retrieve the corresponding label from the protocol file.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Path to the directory containing audio files.\n",
    "        label_file (str): Path to the protocol file with labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - np.ndarray: Extracted features for all audio files.\n",
    "            - np.ndarray: Corresponding labels for the audio files.\n",
    "    \"\"\"\n",
    "    labels = load_labels(label_file)  # Load the labels.\n",
    "    features = []\n",
    "    labels_list = []\n",
    "\n",
    "    for file in tqdm(os.listdir(dataset_path), desc=\"Processing audio files\", unit=\"file\"):\n",
    "        if file.endswith(\".flac\"):  # Check if the file is a .flac audio file.\n",
    "            file_path = os.path.join(dataset_path, file)  # Construct the full file path.\n",
    "            file_id = file.replace(\".flac\", \"\")  # Extract the file ID (without extension).\n",
    "            features.append(extract_features(file_path))  # Extract features from the audio file.\n",
    "            labels_list.append(labels[file_id])  # Append the corresponding label.\n",
    "\n",
    "    return np.array(features), np.array(labels_list)\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "print(\"Loading training data...\")\n",
    "train_features, train_labels = load_and_preprocess_data(DATASET_PATH, LABEL_FILE_PATH)\n",
    "\n",
    "# Scale features\n",
    "# Standardize the features to have zero mean and unit variance for better performance in SVM.\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "# Separate bona fide and spoof data\n",
    "# One-Class SVM is trained only on bona fide data to model genuine behavior.\n",
    "bona_fide_features = train_features[train_labels == \"bonafide\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69803356-e9ea-4a91-a119-e5d36d907509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training One-Class SVM...\n",
      "Loading test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files:  99%|██████████████████████████████████████████████████▌| 71237/71933 [16:13<00:09, 73.21file/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'LA_E_A1051956'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load and preprocess the test dataset\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading test data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m test_features, test_labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTEST_DATASET_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEST_LABEL_FILE_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m test_features \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(test_features)  \u001b[38;5;66;03m# Standardize test features using the same scaler as training.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 91\u001b[0m, in \u001b[0;36mload_and_preprocess_data\u001b[0;34m(dataset_path, label_file)\u001b[0m\n\u001b[1;32m     89\u001b[0m         file_id \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.flac\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Extract the file ID (without extension).\u001b[39;00m\n\u001b[1;32m     90\u001b[0m         features\u001b[38;5;241m.\u001b[39mappend(extract_features(file_path))  \u001b[38;5;66;03m# Extract features from the audio file.\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m         labels_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m]\u001b[49m)  \u001b[38;5;66;03m# Append the corresponding label.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(features), np\u001b[38;5;241m.\u001b[39marray(labels_list)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'LA_E_A1051956'"
     ]
    }
   ],
   "source": [
    "# Train One-Class SVM\n",
    "print(\"Training One-Class SVM...\")\n",
    "ocsvm = OneClassSVM(kernel='rbf', gamma='scale', nu=0.5)  # Use RBF kernel with scale gamma and nu parameter.\n",
    "ocsvm.fit(bona_fide_features)  # Train the SVM using bona fide data.\n",
    "\n",
    "# Load and preprocess the test dataset\n",
    "print(\"Loading test data...\")\n",
    "test_features, test_labels = load_and_preprocess_data(TEST_DATASET_PATH, TEST_LABEL_FILE_PATH)\n",
    "test_features = scaler.transform(test_features)  # Standardize test features using the same scaler as training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1c3d7-8d03-456e-887b-65c650bce4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test dataset\n",
    "print(\"Evaluating model on test data...\")\n",
    "test_scores = ocsvm.decision_function(test_features)  # Compute decision scores for test data.\n",
    "test_predictions = ocsvm.predict(test_features)  # Predict whether each sample is bona fide or spoof.\n",
    "\n",
    "# Map predictions to binary labels\n",
    "# Map SVM predictions (1 = inlier, -1 = outlier) to binary labels (1 = bona fide, 0 = spoof).\n",
    "predicted_labels_test = (test_predictions == 1).astype(int)\n",
    "actual_labels_test = (test_labels == \"bonafide\").astype(int)  # Convert actual labels to binary format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d225fa-e5cf-41de-92f8-02740333bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC AUC for test data\n",
    "roc_auc_test = roc_auc_score(actual_labels_test, test_scores)\n",
    "print(f\"Test ROC AUC Score: {roc_auc_test:.4f}\")\n",
    "\n",
    "# Plot ROC Curve for test data\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(actual_labels_test, test_scores)\n",
    "plt.figure()\n",
    "plt.plot(fpr_test, tpr_test, label=f\"Test ROC Curve (AUC = {roc_auc_test:.4f})\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for One-Class SVM on Test Data\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Save the model and scaler\n",
    "# Persist the trained model and the scaler for future use.\n",
    "with open(\"one_class_svm_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(ocsvm, model_file)\n",
    "\n",
    "with open(\"scaler.pkl\", \"wb\") as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "\n",
    "print(\"Model and scaler saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9815a1-edef-48d2-89fe-afb2a756ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and scaler\n",
    "# Persist the trained model and the scaler for future use.\n",
    "with open(\"OC_SVM_First_Model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(ocsvm, model_file)\n",
    "\n",
    "with open(\"OC_SVM_First_Scaler.pkl\", \"wb\") as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "\n",
    "print(\"Model and scaler saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
